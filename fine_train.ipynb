{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Fine Tuning for Cuttlefish\n",
    "\n",
    "In this notebook, I will attempt to fine tune the VGG16 model for cuttlefish training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.engine import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "from consts import *\n",
    "import glob\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = CLASS_NAMES[CLASS_ID]\n",
    "\n",
    "# load the training data\n",
    "train_path = base_path + 'images/cropped_resized/train/'\n",
    "test_path = base_path + 'images/cropped_resized/test/'\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "n_other = 0\n",
    "\n",
    "n_max = 15000\n",
    "\n",
    "for filepath in glob.glob(train_path + '*.*'):\n",
    "    if USE_GREY:\n",
    "        img = io.imread(filepath, as_gray=USE_GREY)\n",
    "    else:\n",
    "        img = mpimg.imread(filepath)\n",
    "\n",
    "    if class_name in filepath:\n",
    "        train_labels.append(1)\n",
    "        train_images.append(img)\n",
    "    else:\n",
    "        if n_other > n_max:\n",
    "            continue\n",
    "        train_labels.append(0)\n",
    "        train_images.append(img)\n",
    "        n_other += 1\n",
    "\n",
    "for filepath in glob.glob(test_path + '*.*'):\n",
    "    if USE_GREY:\n",
    "        img = io.imread(filepath, as_gray=USE_GREY)\n",
    "    else:\n",
    "        img = mpimg.imread(filepath)\n",
    "    \n",
    "    test_images.append(img)\n",
    "    if class_name in filepath:\n",
    "        test_labels.append(1)\n",
    "    else:\n",
    "        test_labels.append(0)\n",
    "        \n",
    "if USE_GREY:\n",
    "    train_images = np.expand_dims(train_images, axis=3)\n",
    "    test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "print('Positive examples: ' + str(len(train_images) - n_other) + '/' + str(len(train_images)))\n",
    "train_labels = np.array(train_labels)\n",
    "train_images = np.array(train_images)\n",
    "train_images -= 0.5\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_images -= 0.5\n",
    "\n",
    "print(test_images.shape)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1124)])\n",
    "\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, depth)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "for i in range(len(base_model.layers)): \n",
    "    if i == 11:\n",
    "        break\n",
    "    layer = base_model.layers[i]\n",
    "    layer.trainable = False\n",
    "    print('Layer ' + layer.name + ' frozen.')\n",
    "\n",
    "last = base_model.layers[-1].output\n",
    "x = Flatten()(last)\n",
    "x = Dense(512, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(2, activation='softmax', name='predictions')(x)\n",
    "model = Model(base_model.input, x)\n",
    "# We compile the model\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "trdata = ImageDataGenerator()\n",
    "train_data = trdata.flow(x=train_images, y=train_labels, batch_size=batch_size)\n",
    "tsdata = ImageDataGenerator()\n",
    "test_data = tsdata.flow(x=test_images, y=test_labels, batch_size=batch_size)\n",
    "\n",
    "# We train it\n",
    "model.fit(train_data,\n",
    "          validation_data=test_data,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_dir + 'cnn_fine_' + str(CLASS_ID) + '.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit8fa79bb1b4bc48969aa9ecc4887a538a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
